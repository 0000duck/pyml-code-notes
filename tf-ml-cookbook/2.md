# 二、TF 之道

## 计算图上的运算

```py
# 创建张量和占位符
import numpy as np
x_vals = np.array([1., 3., 5., 7., 9.])
x_data = tf.placeholder(tf.float32)
m_const = tf.constant(3.)
my_product = tf.mul(x_data, m_const)
for x_val in x_vals:
    print(sess.run(my_product, feed_dict={x_data: x_val}))
```

![](img/2-1.png)

## 层次嵌套操作

```py
# 定义要馈送的数据和占位符
my_array = np.array([[1., 3., 5., 7., 9.],
                   [-2., 0., 2., 4., 6.],
                   [-6., -3., 0., 3., 6.]])
x_vals = np.array([my_array, my_array + 1])
x_data = tf.placeholder(tf.float32, shape=(3, 5))

# 定义用于矩阵乘和加法的常量
m1 = tf.constant([[1.],[0.],[-1.],[2.],[4.]])
m2 = tf.constant([[2.]])
a1 = tf.constant([[10.]])

# 定义操作，将其加入图中
prod1 = tf.matmul(x_data, m1)
prod2 = tf.matmul(prod1, m2)
add1 = tf.add(prod2, a1)

# 向图馈送数据
for x_val in x_vals:
    print(sess.run(add1, feed_dict={x_data: x_val}))
'''
[[ 102.]
 [  66.]
 [  58.]]
[[ 114.]
 [  78.]
 [  70.]]
'''
```

![](img/2-2.png)

```py
# None 用于不知道维度大小的情况
x_data = tf.placeholder(tf.float32, shape=(3,None))
```

## 使用多个层

```py
# 创建 2d 4x4 图像
# 四个维度分别为图像、高、宽、通道
x_shape = [1, 4, 4, 1]
x_val = np.random.uniform(size=x_shape)

# 创建图像的占位符
x_data = tf.placeholder(tf.float32, shape=x_shape)

# 创建 2x2 的滑动窗口
# 使用 conv2d（卷积操作）
# 长和宽的步长为 2
# 填充为 SAME 模式
# 为了计算均值，窗口的每个元素都是 .25
my_filter = tf.constant(0.25, shape=[2, 2, 1, 1])
my_strides = [1, 2, 2, 1]
mov_avg_layer= tf.nn.conv2d(x_data, my_filter, my_strides,padding='SAME', name='Moving'_Avg_Window')

# 使用自定义层计算 sigmoid(Ax + b)
# squeeze 丢掉大小为 1 的维度
def custom_layer(input_matrix):
    input_matrix_sqeezed = tf.squeeze(input_matrix)
    A = tf.constant([[1., 2.], [-1., 3.]])
    b = tf.constant(1., shape=[2, 2])
    temp1 = tf.matmul(A, input_matrix_sqeezed)
    temp = tf.add(temp1, b) # Ax + b
    return(tf.sigmoid(temp))
    
# 创建命名作用域
# 把新的层放入图中
with tf.name_scope('Custom_Layer') as scope:
    custom_layer1 = custom_layer(mov_avg_layer)

# 馈送 4x4 的图像并运行图
print(sess.run(custom_layer1, feed_dict={x_data: x_val}))
'''
[[ 0.91914582  0.96025133]
 [ 0.87262219  0.9469803 ]]
'''
```

![](img/2-3.png)

## 损失函数

```py
# 回归的损失函数

# 创建 500 个 -1~1 的预测值
# 和 1 个真实值
x_vals = tf.linspace(-1., 1., 500)
target = tf.constant(0.)

# L2 损失又叫欧氏损失
# 是到目标的平方距离
l2_y_vals = tf.square(target - x_vals)
l2_y_out = sess.run(l2_y_vals)

# L1 损失又叫绝对值损失
# 就是将平方换成了绝对值
l1_y_vals = tf.abs(target - x_vals)
l1_y_out = sess.run(l1_y_vals)

# 伪 huber 损失是 huber 损失的连续光滑的估计
# 它选取 L1 和 L2 的最佳值
delta1 = tf.constant(0.25)
phuber1_y_vals = tf.mul(tf.square(delta1), tf.sqrt(1. + 
                        tf.square((target - x_vals)/delta1)) - 1.)
phuber1_y_out = sess.run(phuber1_y_vals)
delta2 = tf.constant(5.)
phuber2_y_vals = tf.mul(tf.square(delta2), tf.sqrt(1. + 
                        tf.square((target - x_vals)/delta2)) - 1.)
phuber2_y_out = sess.run(phuber2_y_vals)

# 分类的损失函数

# 重新定义预测值和真实值
x_vals = tf.linspace(-3., 5., 500)
target = tf.constant(1.)
targets = tf.fill([500,], 1.)

# Hinge 损失用于支持向量机
# 它的标签是 1 和 -1
hinge_y_vals = tf.maximum(0., 1. - tf.mul(target, x_vals))
hinge_y_out = sess.run(hinge_y_vals)

# 也有用于回归的 Hinge 损失
# hinge_y_vals = tf.maximum(0., tf.abs(target, x_vals) - eps)

# 交叉熵又叫 logistic 损失
# 标签是 1 和 0
xentropy_y_vals = - tf.mul(target, tf.log(x_vals)) - tf.mul((1. - target), tf.log(1. - x_vals))
xentropy_y_out = sess.run(xentropy_y_vals)

# sigmoid 交叉熵
# 就是先对预测值计算 sigmoid
# 再计算交叉熵
xentropy_sigmoid_y_vals = tf.nn.sigmoid_cross_entropy_with_logits(x_vals, targets)
xentropy_sigmoid_y_out = sess.run(xentropy_sigmoid_y_vals)

# 带权交叉熵
# 就是先计算交叉熵，再加权
weight = tf.constant(0.5)
xentropy_weighted_y_vals = tf.nn.weighted_cross_entropy_with_logits(x_vals, targets, weight)
xentropy_weighted_y_out = sess.run(xentropy_weighted_y_vals)

# softmax 交叉熵
# 同上，先对预测值计算 softmax
# 再计算交叉熵
unscaled_logits = tf.constant([[1., -3., 10.]])
target_dist = tf.constant([[0.1, 0.02, 0.88]])
softmax_xentropy = tf.nn.softmax_cross_entropy_with_logits(unscaled_logits, target_dist)
print(sess.run(softmax_xentropy))
# [ 1.16012561]

# 稀疏 softmax 交叉熵
# 先对预测值计算 softmax
# 再对真实值计算 one_hot
# 最后计算交叉熵
unscaled_logits = tf.constant([[1., -3., 10.]])
sparse_target_dist = tf.constant([2])
sparse_xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(unscaled_logits, sparse_target_dist)
print(sess.run(sparse_xentropy))
# [ 0.00012564]

# 绘制回归损失
x_array = sess.run(x_vals)
plt.plot(x_array, l2_y_out, 'b-', label='L2 Loss')
plt.plot(x_array, l1_y_out, 'r--', label='L1 Loss')
plt.plot(x_array, phuber1_y_out, 'k-.', label='P-Huber Loss (0.25)')
plt.plot(x_array, phuber2_y_out, 'g:', label='P'-Huber Loss (5.0)')
plt.ylim(-0.2, 0.4)
plt.legend(loc='lower right', prop={'size': 11})
plt.show()

# 绘制分类损失
x_array = sess.run(x_vals)
plt.plot(x_array, hinge_y_out, 'b-', label='Hinge Loss')
plt.plot(x_array, xentropy_y_out, 'r--', label='Cross Entropy Loss')
plt.plot(x_array, xentropy_sigmoid_y_out, 'k-.', label='Cross Entropy Sigmoid Loss')
plt.plot(x_array, xentropy_weighted_y_out, g:', label='Weighted Cross Enropy Loss (x0.5)')
plt.ylim(-1.5, 3)
plt.legend(loc='lower right', prop={'size': 11})
plt.show()
```

![](img/2-4.png)

![](img/2-5.png)
